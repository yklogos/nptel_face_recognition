{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play audio in ipython notebook\n",
    "try:\n",
    "    import winsound\n",
    "except ImportError:\n",
    "    !pip install winsound\n",
    "    import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "from googlesearch import search\n",
    "from PIL import Image, ImageStat\n",
    "import time\n",
    "tt = time.time\n",
    "st = tt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prof', 'first', 'middle']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.12 ms\n"
     ]
    }
   ],
   "source": [
    "text = 'blah blah prof first middle last'.split(' ')\n",
    "idx = text.index('prof')\n",
    "text = text[idx:]\n",
    "text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "# get prof name from thumbnail\n",
    "def save_as_pickle(file_path, file):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(file, f)\n",
    "\n",
    "def load_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "    return file\n",
    "\n",
    "def plot_image_list(img_list, figsize=(12, 12), subplot_n_cols=2):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i,img in enumerate(img_list):\n",
    "        plt.subplot(int(len(img_list)/subplot_n_cols)+1, subplot_n_cols, i+1)\n",
    "        try:\n",
    "            plt.imshow(img)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "def make_rgb_bgr(img):\n",
    "    b,g,r = cv2.split(img)          \n",
    "    rgb_img = cv2.merge([r,g,b]) \n",
    "    return rgb_img\n",
    "        \n",
    "def brightness(img):\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('L')\n",
    "    stat = ImageStat.Stat(img)\n",
    "    return stat.rms[0]\n",
    "\n",
    "def is_valid_img(img, lthresh = 100, hthresh = 200):\n",
    "    bright = brightness(img)\n",
    "    if bright<lthresh or bright>hthresh:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def get_extension_files(path_to_json, ext='.json'):\n",
    "    json_files = [os.path.join(path_to_json, pos_json) for pos_json in os.listdir(path_to_json) if pos_json.endswith(ext)]\n",
    "    return json_files\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def get_prof_name(text, title=False):\n",
    "    hon_list = ['prof','dr', 'by']\n",
    "    ext_list = ['.', ' ']\n",
    "    hon_list = flatten_list([[w+ext for ext in ext_list] for w in hon_list])\n",
    "    \n",
    "    word_before_list = ['assosiate', 'adjunct', 'professor', 'faculty', 'dept.', 'department']\n",
    "    ishon=False\n",
    "    text = text.split(' ')\n",
    "    text_copy = text.copy()\n",
    "    for hon in hon_list:\n",
    "        if hon in text:       \n",
    "            print(f\" honorific in text: {text_copy}\")\n",
    "            idx = text.index(hon)\n",
    "            text = text[idx:]\n",
    "            if title:\n",
    "                text = \" \".join(text)\n",
    "                return text\n",
    "                \n",
    "            else:\n",
    "                # get all words before a specified word\n",
    "                for wb in word_before_list:\n",
    "                    if wb in text:\n",
    "                        wbidx = text.index(wb)\n",
    "                        text = \" \".join(text[:wbidx])\n",
    "                        text = ''.join([x for x in text if x.isalpha() or x in ext_list])  # get rid of non apha chars\n",
    "                        print(f\" honorific and word_brfore in text: {text_copy}\")\n",
    "                        return text\n",
    "                \n",
    "                # if last name is less than 4 letters dont include\n",
    "                if len(text)>3:\n",
    "                    if len(text[3])<4:\n",
    "                        text = text[:3]\n",
    "                    else:\n",
    "                        text = text[:4]\n",
    "                return \" \".join(text)\n",
    "            \n",
    "    return None\n",
    "    \n",
    "def get_name_fom_image(img):\n",
    "    \n",
    "    tesseract_file_path = \"C:/Users/YASH/AppData/Local/Tesseract-OCR/tesseract.exe\"\n",
    "    pytesseract.pytesseract.tesseract_cmd = tesseract_file_path\n",
    "#     img = subimg(img, u=0.7)\n",
    "\n",
    "    # Convert the image to gray scale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Performing OTSU threshold \n",
    "    ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY) \n",
    "\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18)) \n",
    "\n",
    "    # Appplying dilation on the threshold image \n",
    "    dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1) \n",
    "    # dilation = thresh1\n",
    "\n",
    "    # Finding contours \n",
    "    contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL,  \n",
    "                                                     cv2.CHAIN_APPROX_NONE) \n",
    "\n",
    "    # Creating a copy of image \n",
    "    im2 = img.copy() \n",
    "    text = None\n",
    "    for cnt in contours: \n",
    "        x, y, w, h = cv2.boundingRect(cnt) \n",
    "\n",
    "        # Drawing a rectangle on copied image \n",
    "        rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2) \n",
    "\n",
    "        # Cropping the text block for giving input to OCR \n",
    "        cropped = im2[y:y + h, x:x + w] \n",
    "\n",
    "        # Apply OCR on the cropped image \n",
    "        text_sub = pytesseract.image_to_string(cropped)\n",
    "        text_sub = text_sub.lower().replace(\"\\n\",\" \").strip()\n",
    "        if text_sub=='':\n",
    "            continue\n",
    "        text_sub_name = get_prof_name(text_sub)\n",
    "        if text_sub_name is not None:\n",
    "            print(text_sub)\n",
    "            text = text_sub_name\n",
    "            break\n",
    "    \n",
    "    return text\n",
    "\n",
    "def post_processing(img):\n",
    "    norm_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "    norm_img = cv2.normalize(img, norm_img, 0, 255,\n",
    "                             cv2.NORM_MINMAX)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-88764e8bad16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracebacks_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"prof_names.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m# with open(\"vedio_ids.txt\", 'w', encoding='utf-8') as f:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[0mwinsound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14min 3s\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "\n",
    "# # get NAMES ONLY\n",
    "\n",
    "# base_dir = 'C:\\\\Users\\\\YASH\\\\nptel_face_recognition'\n",
    "\n",
    "# full_vedios_dir = os.path.join(base_dir, \"full_vedio\")\n",
    "# known_faces_dir = os.path.join(base_dir, \"known_faces\")\n",
    "# tracebacks_dir = os.path.join(base_dir, \"tracebacks\")\n",
    "# os.makedirs(tracebacks_dir, exist_ok = True)\n",
    "\n",
    "# pkl_files_dir = os.path.join(base_dir, \"pkl_files\")\n",
    "# nptel_channel_name_list = load_from_pickle(os.path.join(pkl_files_dir, \"nptel_channel_name_list.pkl\"))\n",
    "# # num_channels = 2\n",
    "# # num_playlists = 2\n",
    "# # num_vedios = 2\n",
    "    \n",
    "# num_channels = 5\n",
    "# num_playlists = 5\n",
    "# num_vedios = 5\n",
    "\n",
    "# playlist_2_prof_name_dict={}\n",
    "# # for nptel_channel_name in nptel_channel_name_list:\n",
    "# for nptel_channel_name in nptel_channel_name_list[:num_channels]:\n",
    "#     print(f'\\n\\n\\nfor nptel_channel_name {nptel_channel_name}')\n",
    "#     chanel_vedio_dir = os.path.join(full_vedios_dir, nptel_channel_name)\n",
    "#     playlist_path_list = [x[0] for x in os.walk(chanel_vedio_dir)][1:]\n",
    "\n",
    "#     print(f'number of playlist: {len(playlist_path_list)}')\n",
    "#     vedio_ext = '.mp4'\n",
    "    \n",
    "#     namef=0\n",
    "#     namenf=0\n",
    "#     namef_playlist_names_list=[]\n",
    "#     namenf_playlist_names_list=[]\n",
    "#     for playlist_path in playlist_path_list[:num_playlists]:\n",
    "#         gotname = False\n",
    "#         playlistn = playlist_path.split('\\\\')[-1]\n",
    "#         print(f\"\\npaylist: {playlistn}\")\n",
    "#         vedio_path_list = get_extension_files(playlist_path, ext=vedio_ext)\n",
    "#         print(f\"number of vedios: {len(vedio_path_list)}\")\n",
    "        \n",
    "#         vst = 5\n",
    "#         search_interval = 20\n",
    "#         vet = vst + search_interval\n",
    "\n",
    "#         num_f_per_sec = 1\n",
    "#         num_f_inc = 3\n",
    "        \n",
    "\n",
    "#         text_sub = get_prof_name(playlistn.lower(), title=True)\n",
    "#         if text_sub is not None:\n",
    "#             print(f'name: {text_sub} in the title')\n",
    "#             prof_name = text_sub \n",
    "#             gotname = True\n",
    "\n",
    "#         for vedio_path in vedio_path_list[:num_vedios]:\n",
    "#             if gotname:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 num_f_per_sec+=num_f_inc\n",
    "\n",
    "#             vfname = vedio_path.split('\\\\')[-1]\n",
    "#             print(f\"vedio: {vfname}\")\n",
    "#             print(f\"(vst, vet, num_f_per_sec): {(vst, vet, num_f_per_sec)}\")\n",
    "#             video_capture = cv2.VideoCapture(vedio_path)\n",
    "#             fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "#             st = tt()\n",
    "#             i=-1\n",
    "#             while video_capture.isOpened():\n",
    "#                 i+=1\n",
    "#                 if int(i/fps) < vst:\n",
    "#                     ret, frame = video_capture.read()\n",
    "#                     continue\n",
    "\n",
    "#                 if int(i/fps) > vet:\n",
    "#                     break\n",
    "\n",
    "#                 ret, frame = video_capture.read()\n",
    "\n",
    "#                 if i%int(fps/num_f_per_sec)==0:\n",
    "#     #                 print(f\"time(sec): {int(i/fps)}\")\n",
    "#                     if not gotname:\n",
    "#                         text = get_name_fom_image(frame)\n",
    "#                         if text is not None:\n",
    "#                             print(f'name: {text} at time: {int(i/fps)}')\n",
    "#                             prof_name = text\n",
    "#                             gotname = True\n",
    "#                             break\n",
    "\n",
    "#                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "\n",
    "#             video_capture.release()\n",
    "#             cv2.destroyAllWindows()\n",
    "\n",
    "#         if gotname:\n",
    "#             print(f\"face not found for {prof_name}\")\n",
    "#             namef+=1\n",
    "#             namef_playlist_names_list.append(playlistn)\n",
    "#             playlist_2_prof_name_dict[playlistn] = prof_name\n",
    "#         else:\n",
    "#             print(f\"face and name not found for {playlist_path}\")\n",
    "#             namenf+=1\n",
    "#             playlist_2_prof_name_dict[playlistn] = None\n",
    "#             playlist_2_prof_name_dict.append(playlistn)\n",
    "#             namenf+=1\n",
    "    \n",
    "#     chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "#     save_as_pickle(os.path.join(chanel_pkl_files_dir, \"namef_playlist_names_list.pkl\"), namef_playlist_names_list)\n",
    "#     save_as_pickle(os.path.join(chanel_pkl_files_dir, \"namenf_playlist_names_list.pkl\"), namenf_playlist_names_list)\n",
    "#     print(f\"\\nfor channel: {nptel_channel_name}  names found: {namef}, names not found: {namenf}\")    \n",
    "\n",
    "# prof_name_2_playlist_dict = {v: k for k, v in playlist_2_prof_name_dict.items()}\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"prof_name_2_playlist_dict.pkl\"), prof_name_2_playlist_dict)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"playlist_2_prof_name_dict.pkl\"), playlist_2_prof_name_dict)\n",
    "    \n",
    "# winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(tracebacks_dir, \"prof_names.txt\"), 'w', encoding='utf-8') as f:\n",
    "#     f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34min 48s\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "# save faces and names\n",
    "\n",
    "base_dir = 'C:\\\\Users\\\\YASH\\\\nptel_face_recognition'\n",
    "\n",
    "full_vedios_dir = os.path.join(base_dir, \"full_vedio\")\n",
    "known_faces_dir = os.path.join(base_dir, \"known_faces\")\n",
    "tracebacks_dir = os.path.join(base_dir, \"tracebacks\")\n",
    "os.makedirs(tracebacks_dir, exist_ok = True)\n",
    "\n",
    "pkl_files_dir = os.path.join(base_dir, \"pkl_files\")\n",
    "nptel_channel_name_list = load_from_pickle(os.path.join(pkl_files_dir, \"nptel_channel_name_list.pkl\"))\n",
    "# num_channels = 2\n",
    "# num_playlists = 2\n",
    "# num_vedios = 2\n",
    "\n",
    "num_channels = 5\n",
    "num_playlists = 5\n",
    "num_vedios = 5\n",
    "\n",
    "playlist_2_prof_name_dict={}\n",
    "tfacef=0\n",
    "tnamef=0\n",
    "tnamenf=0\n",
    "# for nptel_channel_name in nptel_channel_name_list:\n",
    "for nptel_channel_name in nptel_channel_name_list[:num_channels]:\n",
    "    print(f'\\n\\n\\nfor nptel_channel_name {nptel_channel_name}')\n",
    "    chanel_vedio_dir = os.path.join(full_vedios_dir, nptel_channel_name)\n",
    "    playlist_path_list = [x[0] for x in os.walk(chanel_vedio_dir)][1:]\n",
    "\n",
    "    print(f'number of playlist: {len(playlist_path_list)}')\n",
    "    vedio_ext = '.mp4'\n",
    "    \n",
    "    facef=0\n",
    "    namef=0\n",
    "    namenf=0\n",
    "    facef_playlist_names_list=[]\n",
    "    namef_playlist_names_list=[]\n",
    "    namenf_playlist_names_list=[]\n",
    "    for playlist_path in playlist_path_list[:num_playlists]:\n",
    "        gotname = False\n",
    "        gotface = False\n",
    "        playlistn = playlist_path.split('\\\\')[-1]\n",
    "        print(f\"\\npaylist: {playlistn}\")\n",
    "        vedio_path_list = get_extension_files(playlist_path, ext=vedio_ext)\n",
    "        print(f\"number of vedios: {len(vedio_path_list)}\")\n",
    "        \n",
    "        vst = 5\n",
    "        search_interval = 20\n",
    "        vet = vst + search_interval\n",
    "\n",
    "        num_f_per_sec = 1\n",
    "        num_f_inc = 3\n",
    "        \n",
    "\n",
    "        text_sub = get_prof_name(playlistn.lower(), title=True)\n",
    "        if text_sub is not None:\n",
    "            print(f'name: {text_sub} in the title')\n",
    "            prof_name = text_sub \n",
    "            gotname = True\n",
    "\n",
    "        for vedio_path in vedio_path_list[:num_vedios]:\n",
    "            if gotface:\n",
    "                continue\n",
    "            else:\n",
    "                if gotname:\n",
    "    #                 vst+=search_interval\n",
    "    #                 vet+=search_interval\n",
    "                    num_f_per_sec+=num_f_inc\n",
    "                else:\n",
    "                    num_f_per_sec+=num_f_inc\n",
    "\n",
    "            vfname = vedio_path.split('\\\\')[-1]\n",
    "            print(f\"vedio: {vfname}\")\n",
    "            print(f\"(vst, vet, num_f_per_sec): {(vst, vet, num_f_per_sec)}\")\n",
    "            video_capture = cv2.VideoCapture(vedio_path)\n",
    "            fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "            st = tt()\n",
    "            i=-1\n",
    "            while video_capture.isOpened():\n",
    "                i+=1\n",
    "                if int(i/fps) < vst:\n",
    "                    ret, frame = video_capture.read()\n",
    "                    continue\n",
    "\n",
    "                if int(i/fps) > vet:\n",
    "                    break\n",
    "\n",
    "                ret, frame = video_capture.read()\n",
    "\n",
    "                if i%int(fps/num_f_per_sec)==0:\n",
    "    #                 print(f\"time(sec): {int(i/fps)}\")\n",
    "                    if not gotname:\n",
    "                        text = get_name_fom_image(frame)\n",
    "                        if text is not None:\n",
    "                            print(f'name: {text} at time: {int(i/fps)}')\n",
    "                            prof_name = text\n",
    "                            gotname = True\n",
    "\n",
    "                    else:\n",
    "                        if not is_valid_img(frame):\n",
    "                            continue\n",
    "                        face_locations = face_recognition.face_locations(frame)\n",
    "                        if len(face_locations)==1:\n",
    "                            face_tup = face_locations[0]\n",
    "                            img = frame[face_tup[0]:face_tup[2], face_tup[3]:face_tup[1], :]\n",
    "                            \n",
    "                            # check if encoding is empty\n",
    "                            enc = face_recognition.face_encodings(img)\n",
    "                            if enc==[]:\n",
    "                                continue\n",
    "                                \n",
    "                            image_path = os.path.join(known_faces_dir, prof_name+'.jpg')\n",
    "                            if os.path.exists(image_path):\n",
    "                                print(f\"pic for {prof_name} exists \")\n",
    "                                gotface = True\n",
    "                                break\n",
    "                                \n",
    "                            img = post_processing(img)\n",
    "                            cv2.imwrite(image_path, img) \n",
    "                            gotface = True\n",
    "                            print(f'face at time: {int(i/fps)}')\n",
    "                            break\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        if gotface:\n",
    "            facef+=1\n",
    "            facef_playlist_names_list.append(playlistn)\n",
    "            playlist_2_prof_name_dict[playlistn] = prof_name\n",
    "            \n",
    "        else:\n",
    "            if gotname:\n",
    "                print(f\"face not found for {prof_name}\")\n",
    "                namef+=1\n",
    "                namef_playlist_names_list.append(playlistn)\n",
    "                playlist_2_prof_name_dict[playlistn] = prof_name\n",
    "            else:\n",
    "                print(f\"face and name not found for {playlist_path}\")\n",
    "                playlist_2_prof_name_dict[playlistn] = None\n",
    "                namenf_playlist_names_list.append(playlistn)\n",
    "                namenf+=1\n",
    "    \n",
    "    tfacef+=facef\n",
    "    tnamef+=namef\n",
    "    tnamenf+=namenf\n",
    "    print(f\"\\nfor channel: {nptel_channel_name}  faces found: {facef}, names found: {namef}, names not found: {namenf}\")    \n",
    "\n",
    "    chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "    save_as_pickle(os.path.join(chanel_pkl_files_dir, \"facef_playlist_names_list.pkl\"), facef_playlist_names_list)\n",
    "    save_as_pickle(os.path.join(chanel_pkl_files_dir, \"namef_playlist_names_list.pkl\"), namef_playlist_names_list)\n",
    "    save_as_pickle(os.path.join(chanel_pkl_files_dir, \"namenf_playlist_names_list.pkl\"), namenf_playlist_names_list)\n",
    "\n",
    "print(f\"\\ntotal faces found: {tfacef}, names found: {tnamef}, names not found: {tnamenf}\")\n",
    "prof_name_2_playlist_dict = {v: k for k, v in playlist_2_prof_name_dict.items()}\n",
    "save_as_pickle(os.path.join(pkl_files_dir, \"prof_name_2_playlist_dict.pkl\"), prof_name_2_playlist_dict)\n",
    "save_as_pickle(os.path.join(pkl_files_dir, \"playlist_2_prof_name_dict.pkl\"), playlist_2_prof_name_dict)\n",
    "    \n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63.8 ms\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(tracebacks_dir, \"prof_names_faces.txt\"), 'w', encoding='utf-8') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.97 ms\n"
     ]
    }
   ],
   "source": [
    "# vedio_path = 'C:\\\\Users\\\\YASH\\\\nptel_face_recognition\\\\full_vedio\\\\Cloud Computing\\\\fZ3D6HQrWzs.mp4'\n",
    "# video_capture = cv2.VideoCapture(vedio_path)\n",
    "# fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "# st = tt()\n",
    "# i=-1\n",
    "# while video_capture.isOpened():\n",
    "#     i+=1\n",
    "#     if int(i/fps) < 5:\n",
    "#         ret, frame = video_capture.read()\n",
    "#         continue\n",
    "\n",
    "#     if int(i/fps) > 20:\n",
    "#         break\n",
    "\n",
    "#     ret, frame = video_capture.read()\n",
    "\n",
    "#     if i%fps==0:\n",
    "# #                 print(f\"time(sec): {int(i/fps)}\")\n",
    "#         if not gotname:\n",
    "#             text = get_name_fom_image(frame)\n",
    "#             if text is not None:\n",
    "#                 print(f'name: {text} at time: {int(i/fps)}')\n",
    "#                 prof_name = text\n",
    "#                 gotname = True\n",
    "\n",
    "#         else:\n",
    "#             face_locations = face_recognition.face_locations(frame)\n",
    "#             if len(face_locations)==1:\n",
    "#                 face_tup = face_locations[0]\n",
    "#                 img = frame[face_tup[0]:face_tup[2], face_tup[3]:face_tup[1], :]\n",
    "#                 image_path = os.path.join(known_faces_dir, prof_name+'.jpg')\n",
    "#                 cv2.imwrite(image_path, img) \n",
    "#                 gotface = True\n",
    "#                 print(f'face at time: {int(i/fps)}')\n",
    "#                 break\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
