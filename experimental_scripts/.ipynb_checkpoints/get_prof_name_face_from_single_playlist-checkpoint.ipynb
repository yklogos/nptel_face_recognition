{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play audio in ipython notebook\n",
    "try:\n",
    "    import winsound\n",
    "except ImportError:\n",
    "    !pip install winsound\n",
    "    import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "from googlesearch import search\n",
    "from PIL import Image, ImageStat\n",
    "import time\n",
    "tt = time.time\n",
    "st = tt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prof', 'first', 'middle']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "text = 'blah blah prof first middle last'.split(' ')\n",
    "idx = text.index('prof')\n",
    "text = text[idx:]\n",
    "text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.9 ms\n"
     ]
    }
   ],
   "source": [
    "# get prof name from thumbnail\n",
    "def save_as_pickle(file_path, file):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(file, f)\n",
    "\n",
    "def load_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "    return file\n",
    "\n",
    "def plot_image_list(img_list, figsize=(12, 12), subplot_n_cols=2):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i,img in enumerate(img_list):\n",
    "        plt.subplot(int(len(img_list)/subplot_n_cols)+1, subplot_n_cols, i+1)\n",
    "        try:\n",
    "            plt.imshow(img)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "def make_rgb_bgr(img):\n",
    "    b,g,r = cv2.split(img)          \n",
    "    rgb_img = cv2.merge([r,g,b]) \n",
    "    return rgb_img\n",
    "        \n",
    "def brightness(img):\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('L')\n",
    "    stat = ImageStat.Stat(img)\n",
    "    return stat.rms[0]\n",
    "\n",
    "def is_valid_img(img, lthresh = 100, hthresh = 200):\n",
    "    bright = brightness(img)\n",
    "    if bright<lthresh or bright>hthresh:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def get_extension_files(path_to_json, ext='.json'):\n",
    "    json_files = [os.path.join(path_to_json, pos_json) for pos_json in os.listdir(path_to_json) if pos_json.endswith(ext)]\n",
    "    return json_files\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def get_prof_name(text, title=False):\n",
    "    hon_list = ['prof','dr', 'by']\n",
    "    ext_list = ['.', ':', ' ', '']\n",
    "    hon_list = flatten_list([[w+ext for ext in ext_list] for w in hon_list])\n",
    "    \n",
    "    word_before_list = ['assosiate', 'adjunct', 'professor', 'faculty', 'dept.', 'department']\n",
    "    ishon=False\n",
    "    text = text.split(' ')\n",
    "    text_copy = text.copy()\n",
    "    for hon in hon_list:\n",
    "        if hon in text:       \n",
    "            print(f\" honorific in text: {text_copy}\")\n",
    "            idx = text.index(hon)\n",
    "            text = text[idx:]\n",
    "            if title:\n",
    "                text = \" \".join(text)\n",
    "                return text\n",
    "                \n",
    "            else:\n",
    "                # get all words before a specified word\n",
    "                for wb in word_before_list:\n",
    "                    if wb in text:\n",
    "                        wbidx = text.index(wb)\n",
    "                        text = \" \".join(text[:wbidx])\n",
    "                        text = ''.join([x for x in text if x.isalpha() or x in ext_list])  # get rid of non apha chars\n",
    "                        print(f\" honorific and word_brfore in text: {text_copy}\")\n",
    "                        return text\n",
    "                \n",
    "                # if last name is less than 4 letters dont include\n",
    "                if len(text)>3:\n",
    "                    if len(text[3])<4:\n",
    "                        text = text[:3]\n",
    "                    else:\n",
    "                        text = text[:4]\n",
    "                return \" \".join(text)\n",
    "            \n",
    "    return None\n",
    "    \n",
    "def get_name_fom_image(img):\n",
    "    \n",
    "    tesseract_file_path = \"C:/Users/YASH/AppData/Local/Tesseract-OCR/tesseract.exe\"\n",
    "    pytesseract.pytesseract.tesseract_cmd = tesseract_file_path\n",
    "#     img = subimg(img, u=0.7)\n",
    "\n",
    "    # Convert the image to gray scale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Performing OTSU threshold \n",
    "    ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY) \n",
    "\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18)) \n",
    "\n",
    "    # Appplying dilation on the threshold image \n",
    "    dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1) \n",
    "    # dilation = thresh1\n",
    "\n",
    "    # Finding contours \n",
    "    contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL,  \n",
    "                                                     cv2.CHAIN_APPROX_NONE) \n",
    "\n",
    "    # Creating a copy of image \n",
    "    im2 = img.copy() \n",
    "    text = None\n",
    "    for cnt in contours: \n",
    "        x, y, w, h = cv2.boundingRect(cnt) \n",
    "\n",
    "        # Drawing a rectangle on copied image \n",
    "        rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2) \n",
    "\n",
    "        # Cropping the text block for giving input to OCR \n",
    "        cropped = im2[y:y + h, x:x + w] \n",
    "\n",
    "        # Apply OCR on the cropped image \n",
    "        text_sub = pytesseract.image_to_string(cropped)\n",
    "        text_sub = text_sub.lower().replace(\"\\n\",\" \").strip()\n",
    "        print(f\"pytesseract.image_to_string(cropped): {text_sub}\")\n",
    "        if text_sub=='':\n",
    "            continue\n",
    "        text_sub_name = get_prof_name(text_sub)\n",
    "        if text_sub_name is not None:\n",
    "            print(f\"text_sub_name is not None: {text_sub_name}\")\n",
    "            text = text_sub_name\n",
    "            break\n",
    "    \n",
    "    return text\n",
    "\n",
    "def post_processing(img):\n",
    "    norm_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "    norm_img = cv2.normalize(img, norm_img, 0, 255,\n",
    "                             cv2.NORM_MINMAX)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytesseract.image_to_string(cropped): an prof.tapan k. sengupta dept. of aerospace engineering\n",
      "text split list: ['an', 'prof.tapan', 'k.', 'sengupta', 'dept.', 'of', 'aerospace', 'engineering']\n",
      "pytesseract.image_to_string(cropped): \n",
      "time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "# problems in names\n",
    "\n",
    "# playlist_path = r\"C:\\Users\\YASH\\nptel_face_recognition\\full_vedio\\Aerospace Engineering\\Instability and Transition of Fluid Flows\"\n",
    "# text split list: ['an', 'prof.tapan', 'k.', 'sengupta', 'dept.', 'of', 'aerospace', 'engineering']\n",
    "\n",
    "# playlist_path = r\"C:\\Users\\YASH\\nptel_face_recognition\\full_vedio\\Chemical Engineering\\Particle Characterization (PG)\"\n",
    "# pytesseract.image_to_string(cropped): particle characterization  module -1, lecture -1  introduction: why study particle en rel ete ire ceh ied  paar y eu) eer  due kena} 6 ee rm cra eg ld\n",
    "# text split list: ['particle', 'characterization', '', 'module', '-1,', 'lecture', '-1', '', 'introduction:', 'why', 'study', 'particle', 'en', 'rel', 'ete', 'ire', 'ceh', 'ied', '', 'paar', 'y', 'eu)', 'eer', '', 'due', 'kena}', '6', 'ee', 'rm', 'cra', 'eg', 'ld']\n",
    "# time(sec): 7\n",
    "\n",
    "# playlist_path = r\"C:\\Users\\YASH\\nptel_face_recognition\\full_vedio\\Chemical Engineering\\Mass Transfer Operations I\"\n",
    "# pytesseract.image_to_string(cropped): nee mass transfer operations |  by  carla perenne perey indian institute of technology guwahati\n",
    "# text split list: ['nee', 'mass', 'transfer', 'operations', '|', '', 'by', '', 'carla', 'perenne', 'perey', 'indian', 'institute', 'of', 'technology', 'guwahati']\n",
    "# time(sec): 10\n",
    "\n",
    "# playlist_path = r\"C:\\Users\\YASH\\nptel_face_recognition\\full_vedio\\Computer Science and Engineering\\Cloud Computing\"\n",
    "# pytesseract.image_to_string(cropped): . soumya kani iosh _ ent of computer science and engineering indian institute of technology kharagpur\n",
    "# text split list: ['.', 'soumya', 'kani', 'iosh', '_', 'ent', 'of', 'computer', 'science', 'and', 'engineering', 'indian', 'institute', 'of', 'technology', 'kharagpur']\n",
    "# time(sec): 12\n",
    "\n",
    "\n",
    "\n",
    "# problems in face:\n",
    "\n",
    "# playlist_path = r\"C:\\Users\\YASH\\nptel_face_recognition\\full_vedio\\Aerospace Engineering\\Instability and Transition of Fluid Flows\"\n",
    "# face found if name is known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "# # get NAMES ONLY\n",
    "\n",
    "# base_dir = 'C:\\\\Users\\\\YASH\\\\nptel_face_recognition'\n",
    "# known_faces_dir = os.path.join(base_dir, \"known_faces\")\n",
    "\n",
    "# num_vedios = 1\n",
    "# vedio_ext = \".mp4\"\n",
    "\n",
    "# playlist_path = r\"C:\\Users\\YASH\\nptel_face_recognition\\full_vedio\\Computer Science and Engineering\\Cloud Computing\"\n",
    "# gotname = False\n",
    "# playlistn = playlist_path.split('\\\\')[-1]\n",
    "# print(f\"\\npaylist: {playlistn}\")\n",
    "# vedio_path_list = get_extension_files(playlist_path, ext=vedio_ext)\n",
    "# print(f\"number of vedios: {len(vedio_path_list)}\")\n",
    "\n",
    "# vst = 5\n",
    "# search_interval = 20\n",
    "# vet = vst + search_interval\n",
    "\n",
    "# num_f_per_sec = -2\n",
    "# num_f_inc = 3\n",
    "\n",
    "\n",
    "# text_sub = get_prof_name(playlistn.lower(), title=True)\n",
    "# if text_sub is not None:\n",
    "#     print(f'name: {text_sub} in the title')\n",
    "#     prof_name = text_sub \n",
    "#     gotname = True\n",
    "\n",
    "# img_list = []\n",
    "# for vedio_path in vedio_path_list[:num_vedios]:\n",
    "#     if gotname:\n",
    "#         continue\n",
    "#     else:\n",
    "#         num_f_per_sec+=num_f_inc\n",
    "\n",
    "#     vfname = vedio_path.split('\\\\')[-1]\n",
    "#     print(f\"vedio: {vfname}\")\n",
    "#     print(f\"(vst, vet, num_f_per_sec): {(vst, vet, num_f_per_sec)}\")\n",
    "#     video_capture = cv2.VideoCapture(vedio_path)\n",
    "#     fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "#     st = tt()\n",
    "#     i=-1\n",
    "#     while video_capture.isOpened():\n",
    "#         i+=1\n",
    "#         if int(i/fps) < vst:\n",
    "#             ret, frame = video_capture.read()\n",
    "#             continue\n",
    "\n",
    "#         if int(i/fps) > vet:\n",
    "#             break\n",
    "\n",
    "#         ret, frame = video_capture.read()\n",
    "\n",
    "#         if i%int(fps/num_f_per_sec)==0:\n",
    "#             img_list.append(frame)\n",
    "#             print(f\"time(sec): {int(i/fps)}\")\n",
    "#             if not gotname:\n",
    "#                 text = get_name_fom_image(frame)\n",
    "#                 if text is not None:\n",
    "#                     print(f'name: {text} at time: {int(i/fps)}')\n",
    "#                     prof_name = text\n",
    "#                     gotname = True\n",
    "#                     break\n",
    "\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     video_capture.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "paylist: Industrial Biotechnology\n",
      "number of vedios: 2\n",
      "vedio: 2CqjfuTu4K0.mp4\n",
      "(vst, vet, num_f_per_sec): (5, 25, 1)\n",
      "time(sec): 5\n",
      "time(sec): 6\n",
      "time(sec): 7\n",
      "time(sec): 8\n",
      "time(sec): 9\n",
      "time(sec): 10\n",
      "time(sec): 11\n",
      "time(sec): 12\n",
      "time(sec): 13\n",
      "time(sec): 14\n",
      "time(sec): 15\n",
      "time(sec): 16\n",
      "time(sec): 17\n",
      "time(sec): 18\n",
      "not valid frame\n",
      "time(sec): 19\n",
      "not valid frame\n",
      "time(sec): 20\n",
      "not valid frame\n",
      "time(sec): 21\n",
      "time(sec): 22\n",
      "time(sec): 23\n",
      "time(sec): 24\n",
      "time(sec): 25\n",
      "not valid frame\n",
      "vedio: K2HfqV3sAx0.mp4\n",
      "(vst, vet, num_f_per_sec): (5, 25, 4)\n",
      "time(sec): 5\n",
      "time(sec): 5\n",
      "time(sec): 5\n",
      "time(sec): 5\n",
      "time(sec): 6\n",
      "time(sec): 6\n",
      "time(sec): 6\n"
     ]
    }
   ],
   "source": [
    "# get FACE ONLY\n",
    "\n",
    "base_dir = 'C:\\\\Users\\\\YASH\\\\nptel_face_recognition'\n",
    "known_faces_dir = ''\n",
    "\n",
    "num_vedios = 5\n",
    "vedio_ext = \".mp4\"\n",
    "\n",
    "playlist_path = r\"C:\\Users\\YASH\\nptel_face_recognition\\full_vedio\\Biotechnology\\Industrial Biotechnology\"\n",
    "prof_name = \"prof. debabrata das\"\n",
    "\n",
    "gotname = False\n",
    "playlistn = playlist_path.split('\\\\')[-1]\n",
    "print(f\"\\npaylist: {playlistn}\")\n",
    "vedio_path_list = get_extension_files(playlist_path, ext=vedio_ext)\n",
    "print(f\"number of vedios: {len(vedio_path_list)}\")\n",
    "\n",
    "vst = 5\n",
    "search_interval = 20\n",
    "vet = vst + search_interval\n",
    "\n",
    "num_f_per_sec = -2\n",
    "num_f_inc = 3\n",
    "\n",
    "\n",
    "text_sub = get_prof_name(playlistn.lower(), title=True)\n",
    "if text_sub is not None:\n",
    "    print(f'name: {text_sub} in the title')\n",
    "    prof_name = text_sub \n",
    "    gotname = True\n",
    "\n",
    "img_list = []\n",
    "for vedio_path in vedio_path_list[:num_vedios]:\n",
    "    if gotname:\n",
    "        continue\n",
    "    else:\n",
    "        num_f_per_sec+=num_f_inc\n",
    "\n",
    "    vfname = vedio_path.split('\\\\')[-1]\n",
    "    print(f\"vedio: {vfname}\")\n",
    "    print(f\"(vst, vet, num_f_per_sec): {(vst, vet, num_f_per_sec)}\")\n",
    "    video_capture = cv2.VideoCapture(vedio_path)\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    st = tt()\n",
    "    i=-1\n",
    "    while video_capture.isOpened():\n",
    "        i+=1\n",
    "        if int(i/fps) < vst:\n",
    "            ret, frame = video_capture.read()\n",
    "            continue\n",
    "\n",
    "        if int(i/fps) > vet:\n",
    "            break\n",
    "\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        if i%int(fps/num_f_per_sec)==0:\n",
    "            print(f\"time(sec): {int(i/fps)}\")\n",
    "            img_list.append(frame)\n",
    "            face_locations = face_recognition.face_locations(frame)\n",
    "            if len(face_locations)==1:\n",
    "                if not is_valid_img(frame):\n",
    "                    print(\"not valid frame\")\n",
    "                    continue\n",
    "                \n",
    "                face_tup = face_locations[0]\n",
    "                img = frame[face_tup[0]:face_tup[2], face_tup[3]:face_tup[1], :]\n",
    "\n",
    "                # check if encoding is empty\n",
    "                enc = face_recognition.face_encodings(img)\n",
    "                if enc==[]:\n",
    "                    continue\n",
    "\n",
    "                image_path = os.path.join(known_faces_dir, prof_name+'.jpg')\n",
    "                if os.path.exists(image_path):\n",
    "                    print(f\"pic for {prof_name} exists \")\n",
    "                    gotface = True\n",
    "                    break\n",
    "\n",
    "                img = post_processing(img)\n",
    "                cv2.imwrite(image_path, img) \n",
    "                gotname = True\n",
    "                print(f'face at time: {int(i/fps)}')\n",
    "                break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34min 48s\n"
     ]
    }
   ],
   "source": [
    "# # get face\n",
    "\n",
    "# base_dir = 'C:\\\\Users\\\\YASH\\\\nptel_face_recognition'\n",
    "\n",
    "# full_vedios_dir = os.path.join(base_dir, \"full_vedio\")\n",
    "# known_faces_dir = os.path.join(base_dir, \"known_faces\")\n",
    "# tracebacks_dir = os.path.join(base_dir, \"tracebacks\")\n",
    "# os.makedirs(tracebacks_dir, exist_ok = True)\n",
    "\n",
    "# pkl_files_dir = os.path.join(base_dir, \"pkl_files\")\n",
    "# nptel_channel_name_list = load_from_pickle(os.path.join(pkl_files_dir, \"nptel_channel_name_list.pkl\"))\n",
    "# # num_channels = 2\n",
    "# # num_playlists = 2\n",
    "# # num_vedios = 2\n",
    "\n",
    "# num_channels = 5\n",
    "# num_playlists = 5\n",
    "# num_vedios = 5\n",
    "\n",
    "# playlist_2_prof_name_dict={}\n",
    "# tfacef=0\n",
    "# tnamef=0\n",
    "# tnamenf=0\n",
    "# # for nptel_channel_name in nptel_channel_name_list:\n",
    "# for nptel_channel_name in nptel_channel_name_list[:num_channels]:\n",
    "#     print(f'\\n\\n\\nfor nptel_channel_name {nptel_channel_name}')\n",
    "#     chanel_vedio_dir = os.path.join(full_vedios_dir, nptel_channel_name)\n",
    "#     playlist_path_list = [x[0] for x in os.walk(chanel_vedio_dir)][1:]\n",
    "\n",
    "#     print(f'number of playlist: {len(playlist_path_list)}')\n",
    "#     vedio_ext = '.mp4'\n",
    "    \n",
    "#     facef=0\n",
    "#     namef=0\n",
    "#     namenf=0\n",
    "#     facef_playlist_names_list=[]\n",
    "#     namef_playlist_names_list=[]\n",
    "#     namenf_playlist_names_list=[]\n",
    "#     for playlist_path in playlist_path_list[:num_playlists]:\n",
    "#         gotname = False\n",
    "#         gotface = False\n",
    "#         playlistn = playlist_path.split('\\\\')[-1]\n",
    "#         print(f\"\\npaylist: {playlistn}\")\n",
    "#         vedio_path_list = get_extension_files(playlist_path, ext=vedio_ext)\n",
    "#         print(f\"number of vedios: {len(vedio_path_list)}\")\n",
    "        \n",
    "#         vst = 5\n",
    "#         search_interval = 20\n",
    "#         vet = vst + search_interval\n",
    "\n",
    "#         num_f_per_sec = 1\n",
    "#         num_f_inc = 3\n",
    "        \n",
    "\n",
    "#         text_sub = get_prof_name(playlistn.lower(), title=True)\n",
    "#         if text_sub is not None:\n",
    "#             print(f'name: {text_sub} in the title')\n",
    "#             prof_name = text_sub \n",
    "#             gotname = True\n",
    "\n",
    "#         for vedio_path in vedio_path_list[:num_vedios]:\n",
    "#             if gotface:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 if gotname:\n",
    "#     #                 vst+=search_interval\n",
    "#     #                 vet+=search_interval\n",
    "#                     num_f_per_sec+=num_f_inc\n",
    "#                 else:\n",
    "#                     num_f_per_sec+=num_f_inc\n",
    "\n",
    "#             vfname = vedio_path.split('\\\\')[-1]\n",
    "#             print(f\"vedio: {vfname}\")\n",
    "#             print(f\"(vst, vet, num_f_per_sec): {(vst, vet, num_f_per_sec)}\")\n",
    "#             video_capture = cv2.VideoCapture(vedio_path)\n",
    "#             fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "#             st = tt()\n",
    "#             i=-1\n",
    "#             while video_capture.isOpened():\n",
    "#                 i+=1\n",
    "#                 if int(i/fps) < vst:\n",
    "#                     ret, frame = video_capture.read()\n",
    "#                     continue\n",
    "\n",
    "#                 if int(i/fps) > vet:\n",
    "#                     break\n",
    "\n",
    "#                 ret, frame = video_capture.read()\n",
    "\n",
    "#                 if i%int(fps/num_f_per_sec)==0:\n",
    "#     #                 print(f\"time(sec): {int(i/fps)}\")\n",
    "#                     if not gotname:\n",
    "#                         text = get_name_fom_image(frame)\n",
    "#                         if text is not None:\n",
    "#                             print(f'name: {text} at time: {int(i/fps)}')\n",
    "#                             prof_name = text\n",
    "#                             gotname = True\n",
    "\n",
    "#                     else:\n",
    "#                         if not is_valid_img(frame):\n",
    "#                             continue\n",
    "#                         face_locations = face_recognition.face_locations(frame)\n",
    "#                         if len(face_locations)==1:\n",
    "#                             face_tup = face_locations[0]\n",
    "#                             img = frame[face_tup[0]:face_tup[2], face_tup[3]:face_tup[1], :]\n",
    "                            \n",
    "#                             # check if encoding is empty\n",
    "#                             enc = face_recognition.face_encodings(img)\n",
    "#                             if enc==[]:\n",
    "#                                 continue\n",
    "                                \n",
    "#                             image_path = os.path.join(known_faces_dir, prof_name+'.jpg')\n",
    "#                             if os.path.exists(image_path):\n",
    "#                                 print(f\"pic for {prof_name} exists \")\n",
    "#                                 gotface = True\n",
    "#                                 break\n",
    "                                \n",
    "#                             img = post_processing(img)\n",
    "#                             cv2.imwrite(image_path, img) \n",
    "#                             gotface = True\n",
    "#                             print(f'face at time: {int(i/fps)}')\n",
    "#                             break\n",
    "\n",
    "#                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "\n",
    "#             video_capture.release()\n",
    "#             cv2.destroyAllWindows()\n",
    "\n",
    "#         if gotface:\n",
    "#             facef+=1\n",
    "#             facef_playlist_names_list.append(playlistn)\n",
    "#             playlist_2_prof_name_dict[playlistn] = prof_name\n",
    "            \n",
    "#         else:\n",
    "#             if gotname:\n",
    "#                 print(f\"face not found for {prof_name}\")\n",
    "#                 namef+=1\n",
    "#                 namef_playlist_names_list.append(playlistn)\n",
    "#                 playlist_2_prof_name_dict[playlistn] = prof_name\n",
    "#             else:\n",
    "#                 print(f\"face and name not found for {playlist_path}\")\n",
    "#                 playlist_2_prof_name_dict[playlistn] = None\n",
    "#                 namenf_playlist_names_list.append(playlistn)\n",
    "#                 namenf+=1\n",
    "    \n",
    "#     tfacef+=facef\n",
    "#     tnamef+=namef\n",
    "#     tnamenf+=namenf\n",
    "#     print(f\"\\nfor channel: {nptel_channel_name}  faces found: {facef}, names found: {namef}, names not found: {namenf}\")    \n",
    "\n",
    "#     chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "#     save_as_pickle(os.path.join(chanel_pkl_files_dir, \"facef_playlist_names_list.pkl\"), facef_playlist_names_list)\n",
    "#     save_as_pickle(os.path.join(chanel_pkl_files_dir, \"namef_playlist_names_list.pkl\"), namef_playlist_names_list)\n",
    "#     save_as_pickle(os.path.join(chanel_pkl_files_dir, \"namenf_playlist_names_list.pkl\"), namenf_playlist_names_list)\n",
    "\n",
    "# print(f\"\\ntotal faces found: {tfacef}, names found: {tnamef}, names not found: {tnamenf}\")\n",
    "# prof_name_2_playlist_dict = {v: k for k, v in playlist_2_prof_name_dict.items()}\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"prof_name_2_playlist_dict.pkl\"), prof_name_2_playlist_dict)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"playlist_2_prof_name_dict.pkl\"), playlist_2_prof_name_dict)\n",
    "    \n",
    "# winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
