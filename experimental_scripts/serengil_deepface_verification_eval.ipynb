{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play audio in ipython notebook\n",
    "try:\n",
    "    import winsound\n",
    "except ImportError:\n",
    "    !pip install winsound\n",
    "    import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "from googlesearch import search\n",
    "from PIL import Image, ImageStat\n",
    "import time\n",
    "import logging\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from deepface import DeepFace\n",
    "deepface_logger = logging.getLogger(\"deepface\")\n",
    "deepface_logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "import tqdm\n",
    "class _TQDM(tqdm.tqdm):\n",
    "    def __init__(self, *argv, **kwargs):\n",
    "        kwargs['disable'] = True\n",
    "        if kwargs.get('disable_override', 'def') != 'def':\n",
    "            kwargs['disable'] = kwargs['disable_override']\n",
    "        super().__init__(*argv, **kwargs)\n",
    "tqdm.tqdm = _TQDM\n",
    "tt = time.time\n",
    "st = tt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.9 ms\n"
     ]
    }
   ],
   "source": [
    "# get prof name from thumbnail\n",
    "def save_as_pickle(file_path, file):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(file, f)\n",
    "\n",
    "def load_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "    return file\n",
    "\n",
    "def plot_image_list(img_list, figsize=(12, 12), subplot_n_cols=2):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i,img in enumerate(img_list):\n",
    "        plt.subplot(int(len(img_list)/subplot_n_cols)+1, subplot_n_cols, i+1)\n",
    "        try:\n",
    "            plt.imshow(img)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "def brightness(img):\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('L')\n",
    "    stat = ImageStat.Stat(img)\n",
    "    return stat.rms[0]\n",
    "\n",
    "def is_valid_img(img, lthresh = 100, hthresh = 200):\n",
    "    bright = brightness(img)\n",
    "    print(bright)\n",
    "    if bright<lthresh or bright>hthresh:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def get_extension_files(path_to_json, ext='.json'):\n",
    "    json_files = [os.path.join(path_to_json, pos_json) for pos_json in os.listdir(path_to_json) if pos_json.endswith(ext)]\n",
    "    return json_files\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def post_processing(img):\n",
    "    norm_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "    norm_img = cv2.normalize(img, norm_img, 0, 255,\n",
    "                             cv2.NORM_MINMAX)\n",
    "    return img\n",
    "\n",
    "def change_img_name(strn):\n",
    "    temp = int(int(strn.split(\"/\")[-1][:-4])/100)\n",
    "    return temp\n",
    "\n",
    "def stopPrint(func, *args, **kwargs):\n",
    "    with open(os.devnull,\"w\") as devNull:\n",
    "        original = sys.stdout\n",
    "        sys.stdout = devNull\n",
    "        res = func(*args, **kwargs)\n",
    "        sys.stdout = original \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'C:\\\\Users\\\\YASH\\\\nptel_face_recognition'\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "results_dir = os.path.join(base_dir, \"results\")\n",
    "os.makedirs(results_dir, exist_ok = True)\n",
    "\n",
    "ver = '3'\n",
    "known_faces_dir = os.path.join(data_dir, 'known_faces'+ver)\n",
    "full_vedios_dir = os.path.join(data_dir, 'full_vedio')\n",
    "pkl_files_dir = os.path.join(data_dir, \"pkl_files\")\n",
    "\n",
    "folder_name_2_prof_name_dict = load_from_pickle(os.path.join(pkl_files_dir, \"folder_name_2_prof_name_dict.pkl\"))\n",
    "\n",
    "images_dir_list = [x[0] for x in os.walk(known_faces_dir)][1:]\n",
    "known_face_names = [folder_name_2_prof_name_dict[int(w.split('\\\\')[-1])] for w in images_dir_list]\n",
    "\n",
    "known_face_img_path_nested_list = []\n",
    "for image_dir in images_dir_list:\n",
    "    known_images_path_list = get_extension_files(image_dir, ext='.jpg') \n",
    "    known_face_img_path_nested_list.append(known_images_path_list)\n",
    "\n",
    "# winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.98 ms\n"
     ]
    }
   ],
   "source": [
    "# save_as_pickle(os.path.join(pkl_files_dir, f\"known_face_names\"+ver+\".pkl\"), known_face_names)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, f\"known_images_path_list\"+ver+\".pkl\"), known_images_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "for nptel_channel_name Biotechnology\n",
      "\n",
      "\n",
      "\n",
      "playlist: Bio electricity\n",
      "WARNING:tensorflow:From C:\\Users\\YASH\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing:   0%|                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\YASH\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\YASH\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:27<00:00, 27.93s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.78s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.47s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.84s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.31s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:30<00:00, 30.95s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.07s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:09<00:00,  9.27s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.81s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.26s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:33<00:00, 33.85s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.03s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:15<00:00, 15.67s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.98s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:16<00:00, 16.93s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:43<00:00, 43.40s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.34s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:23<00:00, 23.76s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:26<00:00, 26.33s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:23<00:00, 23.67s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:59<00:00, 59.80s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:31<00:00, 31.77s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "vedio: QiwxdcckPGc.mp4\n",
      "true_name: prof. mainak das\n",
      "\n",
      "unique predicted value counts for model: VGG-Face:\n",
      "[['prof. shalabh ' '5']]\n",
      "\n",
      "accuracy:0.0                 \n",
      "number of predictions: 5\n",
      "\n",
      "unique predicted value counts for model: Facenet:\n",
      "[['prof. mainak das' '1']\n",
      " ['prof. shalabh ' '4']]\n",
      "\n",
      "accuracy:0.2                 \n",
      "number of predictions: 5\n",
      "\n",
      "unique predicted value counts for model: OpenFace:\n",
      "[['dr eue or' '1']\n",
      " ['prof: padma vankar' '1']]\n",
      "\n",
      "accuracy:0.0                 \n",
      "number of predictions: 5\n",
      "\n",
      "unique predicted value counts for model: DeepFace:\n",
      "[['prof. amit basak ' '1']\n",
      " ['prof. indranil sengupta' '1']\n",
      " ['prof. mainak das' '1']\n",
      " ['prof. soumya k. ghosh' '1']\n",
      " ['prof: padma vankar' '1']]\n",
      "\n",
      "accuracy:0.2                 \n",
      "number of predictions: 5\n",
      "\n",
      "unique predicted value counts for model: DeepID:\n",
      "[]\n",
      "\n",
      "accuracy:0.0                 \n",
      "number of predictions: 5\n",
      "\n",
      "unique predicted value counts for model: Dlib:\n",
      "[['prof. shalabh ' '5']]\n",
      "\n",
      "accuracy:0.0                 \n",
      "number of predictions: 5\n",
      "\n",
      "best model: Dlib \n",
      " accuracy:0.2 \n",
      " time: 1643.6999962329865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:38<00:00, 38.23s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:40<00:00, 40.37s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:16<00:00, 16.66s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.88s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:16<00:00, 16.53s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.31s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.44s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.85s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:34<00:00, 34.67s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:23<00:00, 23.30s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.93s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.97s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.88s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:38<00:00, 38.32s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:26<00:00, 26.09s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:34<00:00, 34.35s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:33<00:00, 33.93s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:33<00:00, 33.01s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:44<00:00, 44.29s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:32<00:00, 32.53s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Analyzing: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:51<00:00, 51.89s/it]\n"
     ]
    }
   ],
   "source": [
    "tracebacks_dir = os.path.join(data_dir, \"tracebacks\")\n",
    "os.makedirs(tracebacks_dir, exist_ok = True)\n",
    "\n",
    "pkl_files_dir = os.path.join(data_dir, \"pkl_files\")\n",
    "sgdf_known_faces_dir = os.path.join(data_dir, 'known_faces_sgdf')\n",
    "\n",
    "nptel_channel_name_list = load_from_pickle(os.path.join(pkl_files_dir, \"nptel_channel_name_list.pkl\"))\n",
    "playlist_2_prof_name_dict = load_from_pickle(os.path.join(pkl_files_dir, \"playlist_2_prof_name_dict.pkl\"))\n",
    "\n",
    "known_face_names = load_from_pickle(os.path.join(pkl_files_dir, f\"known_face_names\"+ver+\".pkl\"))\n",
    "known_images_path_list = load_from_pickle(os.path.join(pkl_files_dir, f\"known_images_path_list\"+ver+\".pkl\"))\n",
    "\n",
    "deep_face_metric = \"euclidean\"\n",
    "best_backend = \"opencv\"\n",
    "temp_img_path = \"../data/img.jpg\"\n",
    "serengil_deep_face_models_list = [\"VGG-Face\", \"Facenet\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"Dlib\"]\n",
    "\n",
    "# start after labeled faces\n",
    "# TODO: customize vedio start idx as all vedios dont take images from the first 2 vedios\n",
    "vedio_start_idx = 2\n",
    "# treshold for face verification\n",
    "threshold = 0.25\n",
    "max_pred_cnt = 5\n",
    "num_labeled_faces = 2\n",
    "\n",
    "num_channels = 2\n",
    "num_playlists = 5\n",
    "num_vedios = 5\n",
    "    \n",
    "# num_channels = 5\n",
    "# num_playlists = 5\n",
    "# num_vedios = 5\n",
    "\n",
    "best_model_list = []\n",
    "# for nptel_channel_name in nptel_channel_name_list:\n",
    "for nptel_channel_name in nptel_channel_name_list[1:num_channels]:\n",
    "    print(f'\\n\\n\\n\\nfor nptel_channel_name {nptel_channel_name}')\n",
    "    chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "    facef_playlist_names_list = load_from_pickle(os.path.join(chanel_pkl_files_dir, \"facef_playlist_names_list.pkl\"))\n",
    "\n",
    "    results_chanel_dir = os.path.join(results_dir, nptel_channel_name)\n",
    "    chanel_vedio_dir = os.path.join(full_vedios_dir, nptel_channel_name)\n",
    "    paylist_path_list = [x[0] for x in os.walk(chanel_vedio_dir)][1:]\n",
    "    paylist_name_list = [x.split('\\\\')[-1] for x in paylist_path_list] \n",
    "    \n",
    "    vedio_ext = '.mp4'\n",
    "    \n",
    "    namef=0\n",
    "    namenf=0\n",
    "    namef_playlist_names_list=[]\n",
    "    namenf_playlist_names_list=[]\n",
    "    # for playlist, playlistn in zip(paylist_path_list, paylist_name_list):\n",
    "    for playlist, playlistn in zip(paylist_path_list[:num_playlists], paylist_name_list[:num_playlists]):\n",
    "        print(f\"\\n\\n\\nplaylist: {playlistn}\")\n",
    "        \n",
    "        if playlistn not in playlist_2_prof_name_dict.keys():\n",
    "            print(f\"{playlistn} not in playlist_2_prof_name_dict\")\n",
    "            continue\n",
    "            \n",
    "        true_name = playlist_2_prof_name_dict[playlistn]\n",
    "        if true_name is None:\n",
    "            print(f\"no name for {playlistn}\")\n",
    "            continue\n",
    "            \n",
    "        if true_name not in folder_name_2_prof_name_dict.values():\n",
    "            print(f\"no face for {true_name}\")\n",
    "            continue\n",
    "        \n",
    "        results_playlist_dir = os.path.join(results_chanel_dir, playlistn)\n",
    "        \n",
    "        vedio_path_list = get_extension_files(playlist, ext='.mp4')\n",
    "        vedio_name_list = [x.split('\\\\')[-1] for x in vedio_path_list] \n",
    "        \n",
    "        for vedio_path in vedio_path_list[vedio_start_idx:vedio_start_idx+num_vedios]:\n",
    "            vname = vedio_path.split('\\\\')[-1]\n",
    "\n",
    "            video_capture = cv2.VideoCapture(vedio_path)\n",
    "\n",
    "            vst = 20\n",
    "            vet = 5*60\n",
    "            num_frames_per_sec = 1\n",
    "\n",
    "            fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "            st = tt()\n",
    "            i=-1\n",
    "            pred_cnt = 0\n",
    "            y_pred_list = {model:[] for model in serengil_deep_face_models_list}\n",
    "            names_list_list = {model:[] for model in serengil_deep_face_models_list}\n",
    "            while video_capture.isOpened():\n",
    "                i+=1\n",
    "                if int(i/fps) < vst:\n",
    "                    ret, frame = video_capture.read()\n",
    "                    continue\n",
    "\n",
    "                if int(i/fps) > vet:\n",
    "                    break\n",
    "\n",
    "                 # Grab a single frame of video\n",
    "                ret, frame = video_capture.read()\n",
    "\n",
    "                # process\n",
    "                if i%int(fps/num_frames_per_sec)==0:\n",
    "                    # TODO: PLS find a workaround this is too stupid\n",
    "                    cv2.imwrite(temp_img_path, frame)\n",
    "                    try:\n",
    "                        detected_face = DeepFace.detectFace(temp_img_path, detector_backend = best_backend)\n",
    "                        pred_cnt+=1\n",
    "                    except ValueError:\n",
    "#                     except Exception as e:\n",
    "#                         print(e)\n",
    "                        continue\n",
    "                    \n",
    "                    if pred_cnt>max_pred_cnt:\n",
    "                        break\n",
    "                        \n",
    "                    # for every model, for every labeled img folder, \n",
    "                    # avearge distance from labeled and detected img\n",
    "                    for j, model in enumerate(serengil_deep_face_models_list):\n",
    "                        # TODO: find a way to not print warnings or tqdms\n",
    "                        df = stopPrint(DeepFace.find, \n",
    "                                           img_path = temp_img_path, \n",
    "                                           detector_backend = best_backend,\n",
    "                                           model_name = model,\n",
    "                                           distance_metric = \"euclidean\",\n",
    "                                           enforce_detection = False,\n",
    "                                           db_path = sgdf_known_faces_dir)\n",
    "                        \n",
    "                        df['identity'] = df['identity'].apply(change_img_name)\n",
    "                        df = df.groupby('identity', as_index=False)['distance'].mean()\n",
    "                        if df.empty:\n",
    "                            y_pred_list[j].append(0)\n",
    "                            continue\n",
    "                            \n",
    "                        optim_folder_name = df.sort_values('identity').iloc[0]['identity']\n",
    "                        name = folder_name_2_prof_name_dict[optim_folder_name]\n",
    "                        names_list_dict[model].append(name)\n",
    "                        if name==true_name:\n",
    "                            y_pred_dict[model].append(1)\n",
    "                        else:\n",
    "                            y_pred_dict[model].append(0)\n",
    "\n",
    "                # Hit 'q' on the keyboard to quit!\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            # Release handle to the webcam\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            print(f\"\\n\\nvedio: {vname}\")\n",
    "            print(f\"true_name: {true_name}\")\n",
    "            for j, model in enumerate(serengil_deep_face_models_list):\n",
    "                y_pred = y_pred_dict[model]\n",
    "                names_list = names_list_dict[model]\n",
    "                print(f\"\\nunique predicted value counts for model: {model}:\")\n",
    "                unique, counts = np.unique(np.array(names_list), return_counts=True)\n",
    "                print(np.asarray((unique, counts)).T)\n",
    "                print(f\"\\naccuracy:{np.array(y_pred).mean()} \\\n",
    "                \\nnumber of predictions: {len(y_pred)}\")\n",
    "                \n",
    "            mean_y_pred_list = list(np.array(y_pred_list).mean(axis=1))\n",
    "            best_model_idx = mean_y_pred_list.index(max(mean_y_pred_list))\n",
    "            best_model = serengil_deep_face_models_list[best_model_idx]\n",
    "            best_model_list.append(best_model)\n",
    "            best_acc = mean_y_pred_list[best_model_idx]\n",
    "            print(f\"\\nbest model: {model} \\n accuracy:{best_acc} \\n time: {tt()-st}\")\n",
    "\n",
    "print(\"unique best model contender counts:\")\n",
    "unique, counts = np.unique(np.array(best_model_list), return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "best_model = max(best_model_list, key=best_model_list.count)\n",
    "print(f\"\\nbest of the best model: {best_model}\")\n",
    "\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_distance_list = []\n",
    "# mean_vote_list = []\n",
    "# for img_path_list in known_face_img_path_nested_list:\n",
    "#     vote_list = []\n",
    "#     distance_list = []\n",
    "#     for img_path in img_path_list[:num_labeled_faces]:\n",
    "#         result  = DeepFace.verify(img_path, temp_img_path, \n",
    "#                                   model_name = model, \n",
    "#                                   distance_metric = deep_face_metric,\n",
    "#                                   detector_backend = best_backend,\n",
    "#                                   enforce_detection =False)\n",
    "#         vote_list.append(result[\"verified\"])\n",
    "#         distance_list.append(result[\"distance\"])\n",
    "#     majority_vote = max(vote_list, key=vote_list.count)\n",
    "#     mean_vote_list.append(len[w for w in vote_list if w])\n",
    "#     mean_distance_list.append(np.array(distance_list).mean())\n",
    "\n",
    "# #                         optim_dist_idx =  mean_vote_list.index(max(mean_vote_list))\n",
    "# optim_dist_idx =  mean_distance_list.index(min(mean_distance_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof_name_2_playlist_dict = {'prof. t.k.sengupta': 'Foundation of Scientific Computing', \n",
    "#  None: 'Particle Characterization (PG)',\n",
    "#  'prof. k. p. sinhamahapatra': 'Introduction to Aerodynamics',\n",
    "#  'dr. a. kushari': 'Jet and Rocket Propulsion',\n",
    "#  'prof. bhaskar ot': 'Turbomachinery Aerodynamics',\n",
    "#  'prof. mainak das': 'Bio electricity',\n",
    "#  'dr. p. gopinath ': 'Biomedical nanotechnology',\n",
    "#  'prof. debabrata das': 'Industrial Biotechnology',\n",
    "#  'prof. shamik sen': 'Introduction to Mechanobiology',\n",
    "#  'dr. ton er': 'Introduction To Proteomics',\n",
    "#  'prof s. de': 'Advanced Mathematical Techniques in Chemical Engineering',\n",
    "#  'dr eue or': 'Mass Transfer Operations I',\n",
    "#  'prof. s. ganguly': 'Microscale Transport Processes',\n",
    "#  'prof. gargi das epartment': 'Phase Equilibrium Thermodynamics',\n",
    "#  'prof: padma vankar': 'Advance Analytical Course',\n",
    "#  'prof. debashis ray ': 'Analytical Chemistry',\n",
    "#  'prof. s. dasgupta coma': 'BioChemistry I',\n",
    "#  'prof. a. g. samuelson': 'Introduction to Organometallic Chemistry',\n",
    "#  'prof. amit basak ': 'Stereochemistry',\n",
    "#  'prof. deepak khemani': 'Artificial Intelligence Search Methods for problem Solving',\n",
    "#  'prof. soumya k. ghosh': 'Cloud Computing',\n",
    "#  'prof. indranil sengupta': 'Hardware Modeling using Verilog',\n",
    "#  'dr. yogish sabharwal': 'Introduction to parallel Programming in Open MP',\n",
    "#  'prof. shalabh ': 'Introduction to R Software'}\n",
    "\n",
    "# playlist_2_prof_name_dict = {v: k for k, v in prof_name_2_playlist_dict.items()}\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"prof_name_2_playlist_dict.pkl\"), prof_name_2_playlist_dict)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"playlist_2_prof_name_dict.pkl\"), playlist_2_prof_name_dict)\n",
    "\n",
    "\n",
    "# folder_name_2_prof_name_dict = {0: 'prof. k. p. sinhamahapatra',\n",
    "#  1: 'dr. a. kushari',\n",
    "#  2: 'prof. bhaskar ot',\n",
    "#  3: 'prof. mainak das',\n",
    "#  4: 'dr. p. gopinath ',\n",
    "#  5: 'prof. debabrata das',\n",
    "#  6: 'prof. shamik sen',\n",
    "#  7: 'dr. ton er',\n",
    "#  8: 'prof s. de',\n",
    "#  9: 'dr eue or',\n",
    "#  10: 'prof. s. ganguly',\n",
    "#  11: 'prof. gargi das epartment',\n",
    "#  12: 'prof: padma vankar',\n",
    "#  13: 'prof. debashis ray ',\n",
    "#  14: 'prof. s. dasgupta coma',\n",
    "#  15: 'prof. a. g. samuelson',\n",
    "#  16: 'prof. amit basak ',\n",
    "#  17: 'prof. deepak khemani',\n",
    "#  18: 'prof. soumya k. ghosh',\n",
    "#  19: 'prof. indranil sengupta',\n",
    "#  20: 'prof. shalabh '}\n",
    "\n",
    "# prof_name_2_folder_name_dict = {v: k for k, v in folder_name_2_prof_name_dict.items()}\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"folder_name_2_prof_name_dict.pkl\"), folder_name_2_prof_name_dict)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"prof_name_2_folder_name_dict.pkl\"), prof_name_2_folder_name_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
