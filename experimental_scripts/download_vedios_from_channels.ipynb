{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pytube3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play audio in ipython notebook\n",
    "try:\n",
    "    import winsound\n",
    "except ImportError:\n",
    "    !pip install winsound\n",
    "    import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pickle\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pytube import YouTube\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from lxml import html\n",
    "from googlesearch import search\n",
    "import pytesseract\n",
    "import shutil\n",
    "import youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.98 ms\n"
     ]
    }
   ],
   "source": [
    "def make_dict_from_lists(list1, list2, one2two = True):\n",
    "    if one2two:\n",
    "        final = {list1[i]:list2[i] for i in range(len(list1))}\n",
    "    else:\n",
    "        final = {list2[i]:list1[i] for i in range(len(list1))}\n",
    "\n",
    "def make_rgb_bgr(img):\n",
    "    b,g,r = cv2.split(img)          \n",
    "    rgb_img = cv2.merge([r,g,b]) \n",
    "    return rgb_img\n",
    "\n",
    "def read_bgr(path):\n",
    "    return make_rgb_bgr(cv2.imread(\"sample.jpg\", -1))\n",
    "\n",
    "def imshowg(gray):\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    \n",
    "def subimg(img, u=0,r=1,d=1,l=0):\n",
    "    h = img.shape[0]\n",
    "    b = img.shape[1]\n",
    "    return img[int(h*u):int(h*d), int(b*l):int(b*r)]\n",
    "\n",
    "def url_to_image(url):\n",
    "    try:\n",
    "        resp = urllib.request.urlopen(url)\n",
    "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(url)\n",
    "        \n",
    "def save_as_pickle(file_path, file):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(file, f)\n",
    "\n",
    "def load_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "    return file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.62 ms\n"
     ]
    }
   ],
   "source": [
    "def get_playlists_json_list_from_chanelid(youtube_api_key, channel_id, part = \"snippet\", maxResults = 3):\n",
    "    site_url = f\"https://www.googleapis.com/youtube/v3/playlists?key={youtube_api_key}&channelId={channel_id}&part={part}&order=date&maxResults={maxResults}\"\n",
    "    r = requests.get(site_url)\n",
    "    return r.json()\n",
    "\n",
    "def get_playlists_id_names_list_from_chanelid(youtube_api_key, channel_id, part = \"id,snippet\", maxResults = 3):\n",
    "    site_url = f\"https://www.googleapis.com/youtube/v3/playlists?key={youtube_api_key}&channelId={channel_id}&part={part}&order=date&maxResults={maxResults}\"\n",
    "    r = requests.get(site_url)\n",
    "    r_json = r.json()\n",
    "    playlist_names_list = [w['snippet']['title'] for w in r_json['items']]\n",
    "    playlistid_list = [w['id'] for w in r_json['items']]\n",
    "    return playlistid_list, playlist_names_list\n",
    "\n",
    "def get_vedio_id_list_from_playlistid(youtube_api_key, playlist_id, part = \"id,snippet\", maxResults = 5):\n",
    "    site_url = f\"https://www.googleapis.com/youtube/v3/playlistItems?key={youtube_api_key}&playlistId={playlist_id}&part={part}&order=date&maxResults={maxResults}\"\n",
    "    r = requests.get(site_url)\n",
    "    r_json = r.json()\n",
    "    vedioid_list = [w['snippet']['resourceId']['videoId'] for w in r_json['items']]\n",
    "    return vedioid_list\n",
    "\n",
    "# def get_vedioid_list_thumbnail_from_playlistid(youtube_api_key, playlist_id, part = \"id,snippet\", maxResults = 3):\n",
    "#     site_url = f\"https://www.googleapis.com/youtube/v3/playlistItems?key={youtube_api_key}&playlistId={playlist_id}&part={part}&order=date&maxResults={maxResults}\"\n",
    "#     r = requests.get(site_url)\n",
    "#     r_json = r.json()\n",
    "#     vedioid_list = [w['snippet']['resourceId']['videoId'] for w in r_json['items']]\n",
    "#     thumbnail_url = r_json['items'][0]['snippet']['thumbnails']['maxres']['url']\n",
    "#     return vedioid_list, thumbnail_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.8 ms\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"C:\\\\Users\\\\YASH\\\\nptel_face_recognition\\data\"\n",
    "\n",
    "youtube_vedio_base_url = \"https://www.youtube.com/watch?v=\"\n",
    "youtube_api_key = \"AIzaSyDvP159lNILjQfqj0CN5f2-srIQ5ZYQBxM\"\n",
    "\n",
    "# all nptel channels\n",
    "nptel_channel_name_list = [\"Aerospace Engineering\",\n",
    "                           \"Biotechnology\",\n",
    "                           \"Chemical Engineering\",\n",
    "                           \"Chemistry and Biochemistry\",\n",
    "                           \"Computer Science and Engineering\",\n",
    "                           \"Electrical Engineering\",\n",
    "                           \"Textile Engineering\",\n",
    "                           \"Physics\",\n",
    "                           \"Automobile Engineering\",\n",
    "                           \"Mathematics\",\n",
    "                            ]\n",
    "\n",
    "nptel_channel_id_list = [\"UCiY8ERfD4qvD_-d-VUWh_GA\", \n",
    "                         \"UCbWTmSK7bYM9kRZAdfy_gyg\",\n",
    "                         \"UCqqc1GmsuANsx3s3Y0C-BsQ\",\n",
    "                         \"UCE_U8NURXPMGQKwq_J5jfSA\",\n",
    "                         \"UCxJp9aEteKmOeobEsHXwxAw\",\n",
    "                         \"UCTJn6buigC961hns17ELXAQ\",\n",
    "                         \"UC2IIM0OhqB8o8BzDZs-PKqQ\",\n",
    "                         \"UC9vycSfjzLCR_w1C59VQo5A\",\n",
    "                         \"UCGLlbmSTaLNUPhDwsMe-SgQ\",\n",
    "                         \"UCW6912n7NwlBO7rPTIxHm0w\"\n",
    "                        ]\n",
    "\n",
    "nptel_channel_name_2_id_dict = {n:i for n,i in zip(nptel_channel_name_list, nptel_channel_id_list)}\n",
    "nptel_channel_id_2_name_dict = {i:n for n,i in zip(nptel_channel_name_list, nptel_channel_id_list)}\n",
    "\n",
    "pkl_files_dir = os.path.join(base_dir, \"pkl_files\")\n",
    "# os.makedirs(pkl_files_dir, exist_ok = True)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"nptel_channel_name_list.pkl\"), nptel_channel_name_list)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"nptel_channel_id_list.pkl\"), nptel_channel_id_list)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"nptel_channel_name_2_id_dict.pkl\"), nptel_channel_name_2_id_dict)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"nptel_channel_id_2_name_dict.pkl\"), nptel_channel_id_2_name_dict)\n",
    "\n",
    "ydl = youtube_dl.YoutubeDL({\"outtmpl\": \"%(id)s.%(ext)s\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pkl files for channel: Aerospace Engineering\n",
      "saved pkl files for channel: Biotechnology\n",
      "saved pkl files for channel: Chemical Engineering\n",
      "saved pkl files for channel: Chemistry and Biochemistry\n",
      "saved pkl files for channel: Computer Science and Engineering\n",
      "saved pkl files for channel: Electrical Engineering\n",
      "saved pkl files for channel: Textile Engineering\n",
      "saved pkl files for channel: Physics\n",
      "saved pkl files for channel: Automobile Engineering\n",
      "saved pkl files for channel: Mathematics\n",
      "time: 55 s\n"
     ]
    }
   ],
   "source": [
    "# get playlist names, ids and save as pkl from nptel chanel\n",
    "\n",
    "num_channels = 10\n",
    "num_playlists = 10\n",
    "num_vedios = 3\n",
    "\n",
    "# nptel_channel_name = \"Computer Science and Engineering\"\n",
    "for nptel_channel_name in nptel_channel_name_list:\n",
    "    chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "    nptel_channel_id = nptel_channel_name_2_id_dict[nptel_channel_name]\n",
    "    playlist_id_list, playlist_names_list = get_playlists_id_names_list_from_chanelid(youtube_api_key, nptel_channel_id, \n",
    "                                                                                     part = \"id,snippet\",\n",
    "                                                                                     maxResults = num_playlists)\n",
    "    \n",
    "    os.makedirs(chanel_pkl_files_dir, exist_ok = True)\n",
    "    save_as_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_id_list.pkl\"), playlist_id_list)\n",
    "    save_as_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_names_list.pkl\"), playlist_names_list)\n",
    "    \n",
    "    playlist_name_2_id_dict = {n:i for n,i in zip(playlist_name_list, playlist_id_list)}\n",
    "    playlist_id_2_name_dict = {i:n for n,i in zip(playlist_name_list, playlist_id_list)}\n",
    "    save_as_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_name_2_id_dict.pkl\"), playlist_name_2_id_dict)\n",
    "    save_as_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_id_2_name_dict.pkl\"), playlist_id_2_name_dict)\n",
    "    print(f\"saved pkl files for channel: {nptel_channel_name}\")\n",
    "    \n",
    "    complete_playlist_id_list+= playlist_id_list\n",
    "    complete_playlist_names_list+= playlist_names_list\n",
    "\n",
    "complete_playlist_name_2_id_dict = {n:i for n,i in zip(complete_playlist_names_list, complete_playlist_id_list)}\n",
    "complete_playlist_id_2_name_dict = {n:i for n,i in zip(complete_playlist_names_list, complete_playlist_id_list)}\n",
    "save_as_pickle(os.path.join(pkl_files_dir, \"complete_playlist_name_2_id_dict.pkl\"), complete_playlist_name_2_id_dict)\n",
    "save_as_pickle(os.path.join(pkl_files_dir, \"complete_playlist_id_2_name_dict.pkl\"), complete_playlist_id_2_name_dict)\n",
    "\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "# get vedio names, ids and save as pkl from playlists\n",
    "\n",
    "tracebacks_dir = os.path.join(base_dir, \"tracebacks\")\n",
    "os.makedirs(tracebacks_dir, exist_ok = True)\n",
    "\n",
    "play_list_start_idx = 0\n",
    "num_channels = 5\n",
    "num_playlists = 5\n",
    "num_vedios = 2\n",
    "    \n",
    "for nptel_channel_name in nptel_channel_name_list:\n",
    "    print(f'\\nfor nptel_channel_name {nptel_channel_name}')\n",
    "    chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "    playlist_id_list = load_from_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_id_list.pkl\"))\n",
    "    playlist_names_list = load_from_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_names_list.pkl\"))\n",
    "    print(f'number of playlist: {len(playlist_id_list)}')\n",
    "    \n",
    "    chanel_vedio_dir = os.path.join(full_vedios_dir, nptel_channel_name)\n",
    "    s=0\n",
    "    e=0\n",
    "    for playlist_id, playlist_name in zip(playlist_id_list[play_list_start_idx:], playlist_names_list[play_list_start_idx:]):\n",
    "    # for playlist_id, playlist_name in zip([playlist_id_list[0]], [playlist_names_list[0]]):\n",
    "        playlist_pkl_files_dir = os.path.join(chanel_pkl_files_dir, playlist_name)\n",
    "        try:\n",
    "            os.makedirs(playlist_pkl_files_dir, exist_ok = True)\n",
    "        except Exception as ex:\n",
    "            print(f\"playlist path error: {ex}\")\n",
    "            playlist_id_list.remove(playlist_id)\n",
    "            playlist_names_list.remove(playlist_name)\n",
    "            save_as_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_id_list.pkl\"), playlist_id_list)\n",
    "            save_as_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_names_list.pkl\"), playlist_names_list)\n",
    "            print(f\"removed playlist\")\n",
    "            continue\n",
    "            \n",
    "        vedio_id_list_path = os.path.join(playlist_pkl_files_dir, 'vedio_id_list.pkl')\n",
    "        \n",
    "        if os.path.exists(vedio_id_list_path):\n",
    "            print(f\"{vedio_id_list_path} exists\")\n",
    "            e+=1\n",
    "        else:\n",
    "            vedio_id_list = get_vedio_id_list_from_playlistid(youtube_api_key, playlist_id,\n",
    "                                                             part = \"id,snippet\", \n",
    "                                                             maxResults = num_vedios)\n",
    "            \n",
    "            save_as_pickle(os.path.join(playlist_pkl_files_dir, 'vedio_id_list.pkl'), vedio_id_list)\n",
    "            print(f\"{vedio_id_list_path} saved\")\n",
    "            s+=1\n",
    "        print(f'number of vedios: {len(vedio_id_list)}')\n",
    "    print(f'for nptel_channel_name {nptel_channel_name} saved: {s}, exists: {e}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(tracebacks_dir, \"vedio_ids.txt\"), 'w', encoding='utf-8') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] BhWzgo7qkbE: Downloading webpage\n",
      "[download] Resuming download at byte 152466487\n",
      "[download] BhWzgo7qkbE.mp4 has already been downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unable to rename file: [WinError 32] The process cannot access the file because it is being used by another process: 'BhWzgo7qkbE.mp4.part' -> 'BhWzgo7qkbE.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] vT40FWuvIB8: Downloading webpage\n",
      "[download] Resuming download at byte 160367280\n",
      "[download] vT40FWuvIB8.mp4 has already been downloaded\n",
      "[download] 100% of 152.94MiB\n",
      "[youtube] 2hfaiu6x0ow: Downloading webpage\n",
      "[download] Destination: 2hfaiu6x0ow.mp4\n",
      "[download] 100% of 132.45MiB in 00:34                  \n",
      "[youtube] Lz0xqu3HvD0: Downloading webpage\n",
      "[youtube] Lz0xqu3HvD0: Downloading embed webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to extract JS player URL; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] NCrlyaXMAn8: Downloading webpage\n",
      "[youtube] NCrlyaXMAn8: Downloading embed webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to extract JS player URL; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] NdWTDZ7dg-8: Downloading webpage\n",
      "[youtube] NdWTDZ7dg-8: Downloading embed webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to extract JS player URL; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "# download vedios\n",
    "\n",
    "full_vedios_dir = os.path.join(base_dir, \"full_vedio\")\n",
    "tracebacks_dir = os.path.join(base_dir, \"tracebacks\")\n",
    "os.makedirs(tracebacks_dir, exist_ok = True)\n",
    "\n",
    "play_list_start_idx = 0\n",
    "# num_channels = 2\n",
    "# num_playlists = 2\n",
    "# num_vedios = 2\n",
    "\n",
    "num_channels = 5\n",
    "num_playlists = 5\n",
    "num_vedios = 2\n",
    "    \n",
    "# for nptel_channel_name in nptel_channel_name_list:\n",
    "for nptel_channel_name in nptel_channel_name_list[:num_channels]:\n",
    "    print(f'\\n\\n\\nfor nptel_channel_name {nptel_channel_name}')\n",
    "    chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "    playlist_id_list = load_from_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_id_list.pkl\"))[:num_playlists]\n",
    "    playlist_names_list = load_from_pickle(os.path.join(chanel_pkl_files_dir, \"playlist_names_list.pkl\"))[:num_playlists]\n",
    "    print(f'number of playlist: {len(playlist_id_list)}')\n",
    "    vedio_ext = '.mp4'\n",
    "    \n",
    "    cdown=0\n",
    "    cerr=0\n",
    "    cexis=0\n",
    "    chanel_vedio_dir = os.path.join(full_vedios_dir, nptel_channel_name)\n",
    "    for playlist_id, playlist_name in zip(playlist_id_list, playlist_names_list):\n",
    "#     for playlist_id, playlist_name in zip(playlist_id_list[play_list_start_idx:], playlist_names_list[play_list_start_idx:]):\n",
    "#     for playlist_id, playlist_name in zip([playlist_id_list[0]], [playlist_names_list[0]]):\n",
    "        down=0\n",
    "        err=0\n",
    "        exis=0\n",
    "        print(f'\\nfor playlist {playlist_name}')\n",
    "        playlist_pkl_files_dir = os.path.join(chanel_pkl_files_dir, playlist_name)\n",
    "        vedio_id_list = load_from_pickle(os.path.join(playlist_pkl_files_dir, 'vedio_id_list.pkl'))[:num_vedios]\n",
    "        print(f'number of vedios: {len(vedio_id_list)}')\n",
    "        v_dir = os.path.join(chanel_vedio_dir, playlist_name)\n",
    "        os.makedirs(v_dir, exist_ok = True)\n",
    "        for vid in vedio_id_list:\n",
    "            v_url = youtube_vedio_base_url + vid\n",
    "            v_fname =  vid + vedio_ext\n",
    "            v_path = os.path.join(v_dir, v_fname)\n",
    "            v_name = v_path.split('\\\\')[-1]\n",
    "\n",
    "    #         # pytube\n",
    "    #         try:\n",
    "    #             j+=1\n",
    "    #             video = YouTube(v_url)\n",
    "    #             video.streams.filter(progressive=True).first().download(v_dir)\n",
    "    #         except Exception as e:\n",
    "    #             print(f'failed to extract vedio for {v_url} with error {e} using pytube')\n",
    "\n",
    "            # youtube-dl\n",
    "            try:\n",
    "                if not os.path.exists(v_path):\n",
    "                    ydl.download([v_url])\n",
    "                    shutil.move(v_fname, v_path)\n",
    "                    print(f\"{v_name} downloaded\")\n",
    "                    down+=1\n",
    "                else:\n",
    "                    print(f\"{v_name} already downloaded\")\n",
    "                    exis+=1\n",
    "            except Exception as e:\n",
    "                print(f'failed to extract vedio for {v_url} with error {e} using youtube-dl')\n",
    "                err+=1\n",
    "        cdown+=down\n",
    "        cerr+=err\n",
    "        cexis+=exis\n",
    "        print(f\"for playlist {playlist_name}  downloaded: {down}, error: {err}, exists: {exis}\")\n",
    "        \n",
    "    print(f\"\\nfor channel {nptel_channel_name}  downloaded: {cdown}, error: {cerr}, exists: {cexis}\")\n",
    "\n",
    "with open(os.path.join(tracebacks_dir, \"downloading_vedios.txt\"), 'w', encoding='utf-8') as f:\n",
    "# with open(\"vedio_ids.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(cap.stdout)\n",
    "    \n",
    "winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
