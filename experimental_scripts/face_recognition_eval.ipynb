{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play audio in ipython notebook\n",
    "try:\n",
    "    import winsound\n",
    "except ImportError:\n",
    "    !pip install winsound\n",
    "    import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import face_recognition\n",
    "except:\n",
    "    !pip install face_recognition\n",
    "    import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 952 ms\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pytesseract\n",
    "except:\n",
    "    !pip install pytesseract\n",
    "    import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from googlesearch import search\n",
    "from PIL import Image, ImageStat\n",
    "import time\n",
    "tt = time.time\n",
    "st = tt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7778e3df6b41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mfr_fl_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"number_of_times_to_upsample\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"cnn\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mfr_fe_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"num_jitters\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"large\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# get prof name from thumbnail\n",
    "def save_as_pickle(file_path, file):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(file, f)\n",
    "\n",
    "def load_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "    return file\n",
    "\n",
    "def plot_image_list(img_list, figsize=(12, 12), subplot_n_cols=2):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i,img in enumerate(img_list):\n",
    "        plt.subplot(int(len(img_list)/subplot_n_cols)+1, subplot_n_cols, i+1)\n",
    "        try:\n",
    "            plt.imshow(img)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "def brightness(img):\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('L')\n",
    "    stat = ImageStat.Stat(img)\n",
    "    return stat.rms[0]\n",
    "\n",
    "def is_valid_img(img, lthresh = 100, hthresh = 200):\n",
    "    bright = brightness(img)\n",
    "    print(bright)\n",
    "    if bright<lthresh or bright>hthresh:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def get_extension_files(path_to_json, ext='.json'):\n",
    "    json_files = [os.path.join(path_to_json, pos_json) for pos_json in os.listdir(path_to_json) if pos_json.endswith(ext)]\n",
    "    return json_files\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def post_processing(img):\n",
    "    norm_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "    norm_img = cv2.normalize(img, norm_img, 0, 255,\n",
    "                             cv2.NORM_MINMAX)\n",
    "    return img\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    fr_fl_dict = {\"number_of_times_to_upsample\":3, \"model\":\"cnn\"}\n",
    "    fr_fe_dict = {\"num_jitters\":3, \"model\":\"large\"}\n",
    "else:\n",
    "    fr_fl_dict = {\"number_of_times_to_upsample\":1, \"model\":\"hog\"}\n",
    "    fr_fe_dict = {\"num_jitters\":1, \"model\":\"small\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YASH\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\YASH\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding not found for dr. a. kushari\n",
      "time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'D:\\\\Users\\\\YASH\\\\nptel_face_recognition'\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "results_dir = os.path.join(base_dir, \"results\")\n",
    "os.makedirs(results_dir, exist_ok = True)\n",
    "\n",
    "known_faces_dir = os.path.join(data_dir, 'known_faces')\n",
    "full_vedios_dir = os.path.join(data_dir, 'full_vedio')\n",
    "pkl_files_dir = os.path.join(data_dir, \"pkl_files\")\n",
    "\n",
    "folder_name_2_prof_name_dict = load_from_pickle(os.path.join(pkl_files_dir, \"folder_name_2_prof_name_dict2.pkl\"))\n",
    "\n",
    "images_dir_list = [x[0] for x in os.walk(known_faces_dir)][1:]\n",
    "known_face_names = [folder_name_2_prof_name_dict[int(w.split('\\\\')[-1])] for w in images_dir_list]\n",
    "\n",
    "known_face_images_nested_list = []\n",
    "for image_dir in images_dir_list:\n",
    "    known_images_path_list = get_extension_files(image_dir, ext='.jpg') \n",
    "    known_face_images_nested_list.append([cv2.imread(w)[:, :, ::-1] for w in known_images_path_list])\n",
    "#     known_face_images_nested_list.append([face_recognition.load_image_file(w) for w in known_images_path_list])\n",
    "\n",
    "filter_idx_list=[]\n",
    "known_face_encodings=[]\n",
    "known_face_seprate_encodings=[]\n",
    "for i,(n,nl) in enumerate(zip(known_face_names, known_face_images_nested_list)):\n",
    "    enc_list = []\n",
    "    for img in nl:\n",
    "        known_face_locations = face_recognition.face_locations(img, **fr_fl_dict)\n",
    "        enc = face_recognition.face_encodings(img, known_face_locations = known_face_locations, **fr_fe_dict)\n",
    "        if enc!=[]:\n",
    "            enc_list.append(enc[0])\n",
    "    \n",
    "    seprate_img_arr = np.array(enc_list)\n",
    "    img_arr = np.array(enc_list).mean(axis=0)\n",
    "    if enc_list!=[]:\n",
    "        known_face_encodings.append(img_arr)\n",
    "        known_face_seprate_encodings.append(seprate_img_arr)\n",
    "    else:\n",
    "        print(f\"encoding not found for {n}\")\n",
    "        filter_idx_list.append(i)\n",
    "known_face_names = [known_face_names[i] for i in range(len(known_face_names)) if i not in filter_idx_list]\n",
    "\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"known_face_names.pkl\"), known_face_names)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"known_face_encodings.pkl\"), known_face_encodings)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"known_face_seprate_encodings.pkl\"), known_face_seprate_encodings)\n",
    "\n",
    "# winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "for nptel_channel_name Aerospace Engineering\n",
      "\n",
      "\n",
      "playlist: Foundation of Scientific Computing\n",
      "no face for prof. t.k.sengupta\n",
      "\n",
      "\n",
      "playlist: Instability and Transition of Fluid Flows\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Instability and Transition of Fluid Flows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-87f1424843ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m#             continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\nplaylist: {playlistn}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mtrue_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplaylist_2_prof_name_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mplaylistn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrue_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"no name for {playlistn}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Instability and Transition of Fluid Flows'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 171 ms\n"
     ]
    }
   ],
   "source": [
    "tracebacks_dir = os.path.join(data_dir, \"tracebacks\")\n",
    "os.makedirs(tracebacks_dir, exist_ok = True)\n",
    "\n",
    "pkl_files_dir = os.path.join(data_dir, \"pkl_files\")\n",
    "nptel_channel_name_list = load_from_pickle(os.path.join(pkl_files_dir, \"nptel_channel_name_list.pkl\"))\n",
    "playlist_2_prof_name_dict = load_from_pickle(os.path.join(pkl_files_dir, \"playlist_2_prof_name_dict.pkl\"))\n",
    "\n",
    "# known_face_names = load_from_pickle(os.path.join(pkl_files_dir, \"known_face_names.pkl\"))\n",
    "# known_face_encodings = load_from_pickle(os.path.join(pkl_files_dir, \"known_face_encodings.pkl\"))\n",
    "\n",
    "# start after labeled faces\n",
    "# TODO: custom vedio start idx as all vedios dont take images from the first 2 vedios\n",
    "vedio_start_idx = 2\n",
    "# treshold for face distance\n",
    "threshold = 0.25\n",
    "\n",
    "num_channels = 5\n",
    "num_playlists = 5\n",
    "num_vedios = 5\n",
    "    \n",
    "# num_channels = 5\n",
    "# num_playlists = 5\n",
    "# num_vedios = 5\n",
    "\n",
    "# for nptel_channel_name in nptel_channel_name_list:\n",
    "for nptel_channel_name in nptel_channel_name_list[:num_channels]:\n",
    "    print(f'\\n\\n\\nfor nptel_channel_name {nptel_channel_name}')\n",
    "    chanel_pkl_files_dir = os.path.join(pkl_files_dir, nptel_channel_name)\n",
    "    facef_playlist_names_list = load_from_pickle(os.path.join(chanel_pkl_files_dir, \"facef_playlist_names_list.pkl\"))\n",
    "\n",
    "    results_chanel_dir = os.path.join(results_dir, nptel_channel_name)\n",
    "    chanel_vedio_dir = os.path.join(full_vedios_dir, nptel_channel_name)\n",
    "    paylist_path_list = [x[0] for x in os.walk(chanel_vedio_dir)][1:]\n",
    "    paylist_name_list = [x.split('\\\\')[-1] for x in paylist_path_list] \n",
    "    \n",
    "    vedio_ext = '.mp4'\n",
    "    \n",
    "    namef=0\n",
    "    namenf=0\n",
    "    namef_playlist_names_list=[]\n",
    "    namenf_playlist_names_list=[]\n",
    "    # for playlist, playlistn in zip(paylist_path_list, paylist_name_list):\n",
    "    for playlist, playlistn in zip(paylist_path_list[:num_playlists], paylist_name_list[:num_playlists]):\n",
    "#         if playlistn not in facef_playlist_names_list:\n",
    "#             continue\n",
    "        print(f\"\\n\\nplaylist: {playlistn}\")\n",
    "        true_name = playlist_2_prof_name_dict[playlistn]\n",
    "        if true_name is None:\n",
    "            print(f\"no name for {playlistn}\")\n",
    "            continue\n",
    "            \n",
    "        if true_name not in folder_name_2_prof_name_dict.values():\n",
    "            print(f\"no face for {true_name}\")\n",
    "            continue\n",
    "        \n",
    "        results_playlist_dir = os.path.join(results_chanel_dir, playlistn)\n",
    "        \n",
    "        vedio_path_list = get_extension_files(playlist, ext='.mp4')\n",
    "        vedio_name_list = [x.split('\\\\')[-1] for x in vedio_path_list] \n",
    "        \n",
    "        for vedio_path in vedio_path_list[vedio_start_idx:vedio_start_idx+num_vedios]:\n",
    "            vname = vedio_path.split('\\\\')[-1]\n",
    "\n",
    "            video_capture = cv2.VideoCapture(vedio_path)\n",
    "\n",
    "            # Initialize some variables\n",
    "            face_locations = []\n",
    "            face_encodings = []\n",
    "            face_names = []\n",
    "            process_this_frame = True\n",
    "\n",
    "            vst = 0\n",
    "            vet = 5*60\n",
    "            num_frames_per_sec = 1\n",
    "\n",
    "            fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "            st = tt()\n",
    "            i=-1\n",
    "            y_pred=[]\n",
    "            names_list = []\n",
    "            names_scores_list = []\n",
    "            while video_capture.isOpened():\n",
    "                i+=1\n",
    "                if int(i/fps) < vst:\n",
    "                    ret, frame = video_capture.read()\n",
    "                    continue\n",
    "\n",
    "                if int(i/fps) > vet:\n",
    "                    break\n",
    "\n",
    "                 # Grab a single frame of video\n",
    "                ret, frame = video_capture.read()\n",
    "\n",
    "                # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "                small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "                # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "                rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "                # process\n",
    "                if i%int(fps/num_frames_per_sec)==0:\n",
    "                    face_locations = face_recognition.face_locations(rgb_small_frame, **fr_fl_dict)\n",
    "                    if not len(face_locations)==1:\n",
    "                        continue\n",
    "                \n",
    "                    face_encoding = face_recognition.face_encodings(rgb_small_frame, known_face_locations = known_face_locations, \n",
    "                                                                    **fr_fe_dict)[0]\n",
    "\n",
    "                    # face distances with average encodings\n",
    "                    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "                    # face distances as sum of distances for all faces of a prof\n",
    "#                     face_distances=[]\n",
    "#                     for known_face_encodings_list in known_face_seprate_encodings:\n",
    "#                         face_distances.append(face_recognition.face_distance(known_face_encodings_list, face_encoding).mean())\n",
    "\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "                    name = known_face_names[best_match_index]\n",
    "        \n",
    "#                     if face_distances[best_match_index]<threshold:\n",
    "#                         name = 'unknown'\n",
    "#                     else:\n",
    "#                         name = known_face_names[best_match_index]\n",
    "                    \n",
    "#                     print(f\"true_name: {true_name}\")\n",
    "#                     print(f\"name: {name}\")\n",
    "#                     print(f\"face_distances[best_match_index]: {face_distances[best_match_index]}\")\n",
    "#                     print(f\"time: {int(i/fps)}\")\n",
    "                    \n",
    "                    names_list.append(name)\n",
    "                    names_scores_list.append((name, face_distances[best_match_index]))\n",
    "            \n",
    "                    results_vedio_dir = os.path.join(results_playlist_dir, vname)\n",
    "                \n",
    "                    face_recognition_results_dir = os.path.join(results_vedio_dir, \"face_recogition\")\n",
    "                    tp_dir = os.path.join(face_recognition_results_dir, \"tp\")\n",
    "                    fp_dir = os.path.join(face_recognition_results_dir, \"fp\")\n",
    "                    os.makedirs(tp_dir, exist_ok = True)\n",
    "                    os.makedirs(fp_dir, exist_ok = True)\n",
    "\n",
    "                    if name==true_name:\n",
    "                        y_pred.append(1)\n",
    "#                         image_path = os.path.join(tp_dir, name+'.jpg')\n",
    "#                         cv2.imwrite(image_path, cv2.cvtColor(rgb_small_frame, cv2.COLOR_RGB2BGR))\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "#                         image_path = os.path.join(fp_dir, name+'.jpg')\n",
    "#                         cv2.imwrite(image_path, cv2.cvtColor(rgb_small_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                # Hit 'q' on the keyboard to quit!\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            # Release handle to the webcam\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            save_as_pickle(os.path.join(results_vedio_dir, \"names_scores_list.pkl\"), names_scores_list)\n",
    "            print(f\"\\nvedio: {vname}\")\n",
    "            print(\"unique predicted value counts:\")\n",
    "            unique, counts = np.unique(np.array(names_list), return_counts=True)\n",
    "            print(np.asarray((unique, counts)).T)\n",
    "            print(f\"true_name: {true_name} \\n accuracy:{np.array(y_pred).mean()} \\\n",
    "            \\nnumber of predictions: {len(y_pred)}\")\n",
    "\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof_name_2_playlist_dict = {'prof. t.k.sengupta': 'Foundation of Scientific Computing', \n",
    "#  None: 'Particle Characterization (PG)',\n",
    "#  'prof. k. p. sinhamahapatra': 'Introduction to Aerodynamics',\n",
    "#  'dr. a. kushari': 'Jet and Rocket Propulsion',\n",
    "#  'prof. bhaskar ot': 'Turbomachinery Aerodynamics',\n",
    "#  'prof. mainak das': 'Bio electricity',\n",
    "#  'dr. p. gopinath ': 'Biomedical nanotechnology',\n",
    "#  'prof. debabrata das': 'Industrial Biotechnology',\n",
    "#  'prof. shamik sen': 'Introduction to Mechanobiology',\n",
    "#  'dr. ton er': 'Introduction To Proteomics',\n",
    "#  'prof s. de': 'Advanced Mathematical Techniques in Chemical Engineering',\n",
    "#  'dr eue or': 'Mass Transfer Operations I',\n",
    "#  'prof. s. ganguly': 'Microscale Transport Processes',\n",
    "#  'prof. gargi das epartment': 'Phase Equilibrium Thermodynamics',\n",
    "#  'prof: padma vankar': 'Advance Analytical Course',\n",
    "#  'prof. debashis ray ': 'Analytical Chemistry',\n",
    "#  'prof. s. dasgupta coma': 'BioChemistry I',\n",
    "#  'prof. a. g. samuelson': 'Introduction to Organometallic Chemistry',\n",
    "#  'prof. amit basak ': 'Stereochemistry',\n",
    "#  'prof. deepak khemani': 'Artificial Intelligence Search Methods for problem Solving',\n",
    "#  'prof. soumya k. ghosh': 'Cloud Computing',\n",
    "#  'prof. indranil sengupta': 'Hardware Modeling using Verilog',\n",
    "#  'dr. yogish sabharwal': 'Introduction to parallel Programming in Open MP',\n",
    "#  'prof. shalabh ': 'Introduction to R Software'}\n",
    "\n",
    "# playlist_2_prof_name_dict = {v: k for k, v in prof_name_2_playlist_dict.items()}\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"prof_name_2_playlist_dict.pkl\"), prof_name_2_playlist_dict)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"playlist_2_prof_name_dict.pkl\"), playlist_2_prof_name_dict)\n",
    "\n",
    "\n",
    "# folder_name_2_prof_name_dict = {0: 'prof. k. p. sinhamahapatra',\n",
    "#  1: 'dr. a. kushari',\n",
    "#  2: 'prof. bhaskar ot',\n",
    "#  3: 'prof. mainak das',\n",
    "#  4: 'dr. p. gopinath ',\n",
    "#  5: 'prof. debabrata das',\n",
    "#  6: 'prof. shamik sen',\n",
    "#  7: 'dr. ton er',\n",
    "#  8: 'prof s. de',\n",
    "#  9: 'dr eue or',\n",
    "#  10: 'prof. s. ganguly',\n",
    "#  11: 'prof. gargi das epartment',\n",
    "#  12: 'prof: padma vankar',\n",
    "#  13: 'prof. debashis ray ',\n",
    "#  14: 'prof. s. dasgupta coma',\n",
    "#  15: 'prof. a. g. samuelson',\n",
    "#  16: 'prof. amit basak ',\n",
    "#  17: 'prof. deepak khemani',\n",
    "#  18: 'prof. soumya k. ghosh',\n",
    "#  19: 'prof. indranil sengupta',\n",
    "#  20: 'prof. shalabh '}\n",
    "\n",
    "# prof_name_2_folder_name_dict = {v: k for k, v in folder_name_2_prof_name_dict.items()}\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"folder_name_2_prof_name_dict.pkl\"), folder_name_2_prof_name_dict)\n",
    "# save_as_pickle(os.path.join(pkl_files_dir, \"prof_name_2_folder_name_dict.pkl\"), prof_name_2_folder_name_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
